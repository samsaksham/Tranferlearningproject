{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transferlearning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7nVhInIavKFIHZE2mg40w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsaksham/Tranferlearningproject/blob/master/Transferlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddu0y_7Jre3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "26df3a18-0db1-4a06-fec4-96ed6dc52026"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from keras.applications import VGG16\n",
        "\n",
        "img_rows = 224\n",
        "img_cols = 224 \n",
        "\n",
        "#first load the VGG16 model\n",
        "basic_model = VGG16(weights = 'imagenet', \n",
        "                 include_top = False, \n",
        "                 input_shape = (img_rows, img_cols, 3))\n",
        "\n",
        "for (i,layer) in enumerate(basic_model.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "0 InputLayer False\n",
            "1 Conv2D True\n",
            "2 Conv2D True\n",
            "3 MaxPooling2D True\n",
            "4 Conv2D True\n",
            "5 Conv2D True\n",
            "6 MaxPooling2D True\n",
            "7 Conv2D True\n",
            "8 Conv2D True\n",
            "9 Conv2D True\n",
            "10 MaxPooling2D True\n",
            "11 Conv2D True\n",
            "12 Conv2D True\n",
            "13 Conv2D True\n",
            "14 MaxPooling2D True\n",
            "15 Conv2D True\n",
            "16 Conv2D True\n",
            "17 Conv2D True\n",
            "18 MaxPooling2D True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF_RBYiX1fSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWaImMttw5jF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "71cff79f-7094-482c-f230-e1640f6b4eaf"
      },
      "source": [
        "\n",
        "\n",
        "# Here we freeze the last 4 layers \n",
        "for layer in basic_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# Let's print our layers \n",
        "for (i,layer) in enumerate(basic_model.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 InputLayer False\n",
            "1 Conv2D False\n",
            "2 Conv2D False\n",
            "3 MaxPooling2D False\n",
            "4 Conv2D False\n",
            "5 Conv2D False\n",
            "6 MaxPooling2D False\n",
            "7 Conv2D False\n",
            "8 Conv2D False\n",
            "9 Conv2D False\n",
            "10 MaxPooling2D False\n",
            "11 Conv2D False\n",
            "12 Conv2D False\n",
            "13 Conv2D False\n",
            "14 MaxPooling2D False\n",
            "15 Conv2D False\n",
            "16 Conv2D False\n",
            "17 Conv2D False\n",
            "18 MaxPooling2D False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3b2ykdGzBlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def addingTopModel(bottom_model, num_classes, D=256):\n",
        "    \n",
        "    top_model = bottom_model.output\n",
        "    top_model = Flatten(name = \"flatten\")(top_model)\n",
        "    top_model = Dense(D, activation = \"relu\")(top_model)\n",
        "    top_model = Dropout(0.3)(top_model)\n",
        "    top_model = Dense(num_classes, activation = \"softmax\")(top_model)\n",
        "    return addingTop_model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljp02mRbzJJ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "d36642df-9482-4a62-8450-7ddd8effe526"
      },
      "source": [
        "#Lets add our FC Head back onto VGG\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "num_classes = 5\n",
        "\n",
        "FC_Head = addTopModel(basic_model, num_classes)\n",
        "\n",
        "modelnew = Model(inputs=basic_model.input, outputs=FC_Head)\n",
        "\n",
        "print(modelnew.summary())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 21,138,757\n",
            "Trainable params: 21,138,757\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15R8Ie8VzMKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "33a5cfdc-2e90-4f24-a82e-75dfff131c85"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/train'\n",
        "validation_data_dir = '/content/drive/My Drive/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Change the batchsize according to your system RAM\n",
        "train_batchsize = 16\n",
        "val_batchsize = 10\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=train_batchsize,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=val_batchsize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 93 images belonging to 5 classes.\n",
            "Found 25 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVmIbKZe1_Yi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "ed7319f8-48ef-4da7-c74a-3f99fa4ece19"
      },
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "                   \n",
        "checkpoint = ModelCheckpoint(\"image_celeb.h5\", monitor=\"val_loss\",mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3,\n",
        "                          verbose = 1,restore_best_weights = True)\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint]\n",
        "\n",
        "# Note we use a very small learning rate \n",
        "modelnew.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = RMSprop(lr = 0.001),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "nb_train_samples = 93\n",
        "nb_validation_samples = 25\n",
        "epochs = 10\n",
        "batch_size = 9\n",
        "\n",
        "history = modelnew.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = nb_validation_samples // batch_size)\n",
        "\n",
        "modelnew.save(\"image_celeb.h5\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 96s 10s/step - loss: 11.8360 - accuracy: 0.1975 - val_loss: 2.5948 - val_accuracy: 0.3000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.59481, saving model to image_celeb.h5\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 84s 8s/step - loss: 2.3864 - accuracy: 0.4371 - val_loss: 4.7552 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 2.59481\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 87s 9s/step - loss: 2.2026 - accuracy: 0.4076 - val_loss: 4.4312 - val_accuracy: 0.0667\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 2.59481\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 88s 9s/step - loss: 1.6679 - accuracy: 0.4904 - val_loss: 1.6212 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.59481 to 1.62117, saving model to image_celeb.h5\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 86s 9s/step - loss: 1.0113 - accuracy: 0.6494 - val_loss: 3.0422 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.62117\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 86s 9s/step - loss: 1.3419 - accuracy: 0.5909 - val_loss: 0.4267 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.62117 to 0.42665, saving model to image_celeb.h5\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 87s 9s/step - loss: 1.0777 - accuracy: 0.5390 - val_loss: 0.9516 - val_accuracy: 0.6500\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.42665\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 87s 9s/step - loss: 0.8189 - accuracy: 0.7006 - val_loss: 2.4695 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.42665\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 85s 9s/step - loss: 1.2170 - accuracy: 0.5844 - val_loss: 0.0601 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.42665 to 0.06010, saving model to image_celeb.h5\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 87s 9s/step - loss: 0.9218 - accuracy: 0.6818 - val_loss: 0.3087 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.06010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plebl0yL5MEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6f19339f-3adf-4bb5-99a1-5659801b7a4e"
      },
      "source": [
        "from keras.models import load_model\n",
        "classifier = load_model('image_celeb.h5')\n",
        "\n",
        "#Testing the Model\n",
        "%matplotlib inline\n",
        "#The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "five_celeb_dict = {\"[0]\": \"ben_afflek\", \n",
        "                      \"[1]\": \"elton_john\",\n",
        "                      \"[2]\": \"jerry_seinfeld\",\n",
        "                      \"[3]\": \"madonna\",\n",
        "                      \"[4]\": \"mindy_kaling\",\n",
        "                     }\n",
        "\n",
        "five_celeb_dict_n = {\"ben_afflek\": \"ben_afflek\", \n",
        "                      \"elton_john\": \"elton_john\",\n",
        "                      \"jerry_seinfeld\": \"jerry_seinfeld\",\n",
        "                      \"madonna\": \"madonna\",\n",
        "                      \"mindy_kaling\": \"mindy_kaling\",\n",
        "                      }\n",
        "\n",
        "\n",
        "def draw_test(name, pred, im):\n",
        "    celeb =five_celeb_dict[str(pred)]\n",
        "    BLACK = [0,0,0]\n",
        "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
        "    cv2.putText(expanded_image, celeb, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
        "    cv2.imshow(name, expanded_image)\n",
        "\n",
        "def getRandomImage(path):\n",
        "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
        "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
        "    random_directory = np.random.randint(0,len(folders))\n",
        "    path_class = folders[random_directory]\n",
        "    print(\"Class - \" + five_celeb_dict_n[str(path_class)])\n",
        "    file_path = path + path_class\n",
        "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
        "    random_file_index = np.random.randint(0,len(file_names))\n",
        "    image_name = file_names[random_file_index]\n",
        "    return cv2.imread(file_path+\"/\"+image_name)    \n",
        "\n",
        "for i in range(0,10):\n",
        "    input_im = getRandomImage(\"/content/drive/My Drive/val/\")\n",
        "    input_original = input_im.copy()\n",
        "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
        "    input_im = input_im / 255.\n",
        "    input_im = input_im.reshape(1,224,224,3) \n",
        "    \n",
        "  \n",
        "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
        "    \n",
        "  "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class - jerry_seinfeld\n",
            "Class - jerry_seinfeld\n",
            "Class - elton_john\n",
            "Class - mindy_kaling\n",
            "Class - ben_afflek\n",
            "Class - madonna\n",
            "Class - madonna\n",
            "Class - ben_afflek\n",
            "Class - jerry_seinfeld\n",
            "Class - mindy_kaling\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}